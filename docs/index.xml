<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>João Blasques | AI-Enabled Data Engineer</title><link>https://joaoblasques.com/</link><description>Recent content on João Blasques | AI-Enabled Data Engineer</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 21 Jun 2025 09:30:00 +0100</lastBuildDate><atom:link href="https://joaoblasques.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Pipeline Orchestration using Kestra</title><link>https://joaoblasques.com/post/data-pipeline-orchestration-kestra/</link><pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate><guid>https://joaoblasques.com/post/data-pipeline-orchestration-kestra/</guid><description>&lt;h2 id="project-overview">Project Overview&lt;/h2>
&lt;p>This &lt;a href="https://github.com/joaoblasques/data-pipeline-orchestration-kestra">repository&lt;/a> demonstrates workflow orchestration for data engineering pipelines using &lt;a href="https://kestra.io/">Kestra&lt;/a>. It guides users through building, running, and scheduling data pipelines that extract, transform, and load (ETL) data both locally (with PostgreSQL) and in the cloud (with Google Cloud Platform). The project is hands-on and includes conceptual explanations, infrastructure setup, and several example pipeline flows.&lt;/p>
&lt;hr>
&lt;h2 id="key-concepts">Key Concepts&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Workflow Orchestration:&lt;/strong> Automating and managing complex workflows with dependencies, retries, logging, and monitoring.&lt;/li>
&lt;li>&lt;strong>Kestra:&lt;/strong> An orchestration platform with a user-friendly UI and YAML-based workflow definitions (called &amp;ldquo;flows&amp;rdquo;).&lt;/li>
&lt;li>&lt;strong>Data Lake &amp;amp; Data Warehouse:&lt;/strong> Demonstrates moving data from raw storage (GCS) to structured analytics (BigQuery).&lt;/li>
&lt;/ul></description></item><item><title>Orchestrating Data Pipelines with Apache Airflow: A Comprehensive Guide</title><link>https://joaoblasques.com/post/data-pipeline-orchestration-airflow/</link><pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate><guid>https://joaoblasques.com/post/data-pipeline-orchestration-airflow/</guid><description>&lt;h2 id="project-overview">Project Overview&lt;/h2>
&lt;p>This &lt;a href="https://github.com/joaoblasques/data-pipeline-orchestration-airflow">repository&lt;/a> serves as a practical guide to building and orchestrating robust data pipelines using Apache Airflow. It covers essential concepts from basic workflow management to advanced deployments with Google Cloud Platform (GCP) and Kubernetes.&lt;/p>
&lt;hr>
&lt;h2 id="key-concepts">Key Concepts&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Workflow Orchestration:&lt;/strong> Automating and managing complex data workflows with dependencies, scheduling, retries, and monitoring using Apache Airflow.&lt;/li>
&lt;li>&lt;strong>DAGs (Directed Acyclic Graphs):&lt;/strong> The core abstraction in Airflow for defining task dependencies, execution order, and workflow logic.&lt;/li>
&lt;li>&lt;strong>Extensible Operators &amp;amp; Integrations:&lt;/strong> Leveraging Airflow&amp;rsquo;s wide range of built-in operators and custom plugins to interact with databases, cloud services (GCP, Kubernetes), and external systems.&lt;/li>
&lt;li>&lt;strong>Scalable Deployments:&lt;/strong> Running Airflow locally for prototyping, or deploying on cloud and Kubernetes for production-scale, resilient, and distributed data pipeline execution.&lt;/li>
&lt;/ul></description></item><item><title>Simple Data Pipeline</title><link>https://joaoblasques.com/post/data-pipeline-simple/</link><pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate><guid>https://joaoblasques.com/post/data-pipeline-simple/</guid><description>&lt;h2 id="project-overview">Project Overview&lt;/h2>
&lt;p>This &lt;a href="https://github.com/joaoblasques/data-pipeline-simple">repository&lt;/a> provides a comprehensive, step-by-step guide to building a simple data engineering pipeline using containerization (Docker), orchestration (Docker Compose), and Infrastructure as Code (Terraform), with a focus on ingesting and processing NYC taxi data. The project is hands-on and includes conceptual explanations, infrastructure setup, and several example pipeline flows.&lt;/p>
&lt;p>This project is a practical template for data engineers to learn and implement containerized data pipelines, local and cloud database management, and automated cloud infrastructure provisioning using modern tools like Docker, Docker Compose, and Terraform. It is especially useful for those looking to understand the end-to-end workflow from local prototyping to cloud deployment in a reproducible, automated way.&lt;/p></description></item><item><title>Skills &amp; Expertise</title><link>https://joaoblasques.com/skills/</link><pubDate>Fri, 20 Jun 2025 16:03:08 +0100</pubDate><guid>https://joaoblasques.com/skills/</guid><description>&lt;h2 id="technical-skills-overview">Technical Skills Overview&lt;/h2>
&lt;p>I&amp;rsquo;ve developed a diverse set of technical skills throughout my career, focusing on data engineering, machine learning, and cloud technologies. Below is a detailed breakdown of my expertise areas.&lt;/p>
&lt;h3 id="skill-level-legend">Skill Level Legend&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Expert&lt;/strong>: Deep knowledge with 5+ years of experience, can architect solutions and mentor others&lt;/li>
&lt;li>&lt;strong>Advanced&lt;/strong>: Strong working knowledge, can implement complex solutions independently&lt;/li>
&lt;li>&lt;strong>Intermediate&lt;/strong>: Good understanding, can work with guidance on complex tasks&lt;/li>
&lt;li>&lt;strong>Beginner&lt;/strong>: Basic understanding, actively learning&lt;/li>
&lt;/ul>
&lt;h2 id="data-engineering">Data Engineering&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Skill&lt;/th>
 &lt;th>Proficiency&lt;/th>
 &lt;th>Description&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>ETL/ELT Pipeline Design&lt;/td>
 &lt;td>&lt;strong>Expert&lt;/strong>&lt;/td>
 &lt;td>Design and implementation of robust data pipelines for batch and streaming data&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Data Modeling&lt;/td>
 &lt;td>&lt;strong>Expert&lt;/strong>&lt;/td>
 &lt;td>Schema design, dimensional modeling, data warehousing concepts&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Stream Processing&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Real-time data processing and analytics frameworks&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Data Governance&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Data quality, lineage, metadata management, compliance&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Data Orchestration&lt;/td>
 &lt;td>&lt;strong>Expert&lt;/strong>&lt;/td>
 &lt;td>Workflow management and job scheduling&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="tools--technologies">Tools &amp;amp; Technologies&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Apache Ecosystem&lt;/strong>: Spark, Kafka, NiFi, Hadoop (HDFS, YARN)&lt;/li>
&lt;li>&lt;strong>Workflow Orchestration&lt;/strong>: Airflow, Dagster, Prefect&lt;/li>
&lt;li>&lt;strong>Data Warehousing&lt;/strong>: Snowflake, BigQuery, Redshift&lt;/li>
&lt;li>&lt;strong>Data Transformation&lt;/strong>: dbt, Dataform&lt;/li>
&lt;li>&lt;strong>Data Quality&lt;/strong>: Great Expectations, dbt tests, custom frameworks&lt;/li>
&lt;/ul>
&lt;h2 id="machine-learning--ai">Machine Learning &amp;amp; AI&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Skill&lt;/th>
 &lt;th>Proficiency&lt;/th>
 &lt;th>Description&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>ML Model Development&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Developing and training machine learning models for various use cases&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Feature Engineering&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Creating effective features from raw data for ML models&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Natural Language Processing&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Text processing, sentiment analysis, entity extraction&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>MLOps&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>ML model deployment, monitoring, and lifecycle management&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Deep Learning&lt;/td>
 &lt;td>&lt;strong>Intermediate&lt;/strong>&lt;/td>
 &lt;td>Neural networks for complex pattern recognition tasks&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="tools--technologies-1">Tools &amp;amp; Technologies&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>ML Frameworks&lt;/strong>: Scikit-learn, TensorFlow, PyTorch&lt;/li>
&lt;li>&lt;strong>NLP Libraries&lt;/strong>: spaCy, NLTK, Hugging Face Transformers&lt;/li>
&lt;li>&lt;strong>ML Platforms&lt;/strong>: MLflow, Kubeflow, SageMaker&lt;/li>
&lt;li>&lt;strong>Feature Stores&lt;/strong>: Feast, Tecton&lt;/li>
&lt;li>&lt;strong>Model Monitoring&lt;/strong>: Evidently AI, WhyLabs, custom solutions&lt;/li>
&lt;/ul>
&lt;h2 id="cloud--infrastructure">Cloud &amp;amp; Infrastructure&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Skill&lt;/th>
 &lt;th>Proficiency&lt;/th>
 &lt;th>Description&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>AWS&lt;/td>
 &lt;td>&lt;strong>Expert&lt;/strong>&lt;/td>
 &lt;td>Comprehensive knowledge of AWS services and architecture patterns&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>GCP&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Strong experience with Google Cloud data services&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Azure&lt;/td>
 &lt;td>&lt;strong>Intermediate&lt;/strong>&lt;/td>
 &lt;td>Working knowledge of key Azure data services&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>IaC&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Infrastructure as code for cloud resource provisioning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Containerization&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Container technologies for consistent deployments&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="tools--technologies-2">Tools &amp;amp; Technologies&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>AWS&lt;/strong>: S3, Lambda, Glue, EMR, Redshift, Kinesis, Athena, SageMaker&lt;/li>
&lt;li>&lt;strong>GCP&lt;/strong>: BigQuery, Dataflow, Pub/Sub, Dataproc, Vertex AI&lt;/li>
&lt;li>&lt;strong>IaC&lt;/strong>: Terraform, CloudFormation, Pulumi&lt;/li>
&lt;li>&lt;strong>Containerization&lt;/strong>: Docker, Kubernetes, ECS&lt;/li>
&lt;li>&lt;strong>CI/CD&lt;/strong>: GitHub Actions, Jenkins, GitLab CI&lt;/li>
&lt;/ul>
&lt;h2 id="programming-languages">Programming Languages&lt;/h2>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Language&lt;/th>
 &lt;th>Proficiency&lt;/th>
 &lt;th>Focus Areas&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>Python&lt;/td>
 &lt;td>&lt;strong>Expert&lt;/strong>&lt;/td>
 &lt;td>Data engineering, ML/AI, automation, web backends&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>SQL&lt;/td>
 &lt;td>&lt;strong>Expert&lt;/strong>&lt;/td>
 &lt;td>Data querying, analysis, optimization&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Scala&lt;/td>
 &lt;td>&lt;strong>Intermediate&lt;/strong>&lt;/td>
 &lt;td>Spark applications, data processing&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Java&lt;/td>
 &lt;td>&lt;strong>Intermediate&lt;/strong>&lt;/td>
 &lt;td>Enterprise applications, backend services&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>Bash/Shell&lt;/td>
 &lt;td>&lt;strong>Advanced&lt;/strong>&lt;/td>
 &lt;td>Automation, system administration&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="tools--technologies-3">Tools &amp;amp; Technologies&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Python Ecosystem&lt;/strong>: Pandas, NumPy, Matplotlib, Flask, FastAPI&lt;/li>
&lt;li>&lt;strong>SQL Dialects&lt;/strong>: PostgreSQL, MySQL, T-SQL, BigQuery SQL&lt;/li>
&lt;li>&lt;strong>Development&lt;/strong>: Git, GitHub, VS Code, PyCharm, Jupyter&lt;/li>
&lt;/ul>
&lt;h2 id="methodologies--best-practices">Methodologies &amp;amp; Best Practices&lt;/h2>
&lt;h3 id="software-development">Software Development&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Agile Development&lt;/strong>: Scrum, Kanban, iterative development approaches&lt;/li>
&lt;li>&lt;strong>CI/CD&lt;/strong>: Continuous integration and deployment practices&lt;/li>
&lt;li>&lt;strong>Test-Driven Development&lt;/strong>: Writing tests before implementation&lt;/li>
&lt;li>&lt;strong>Code Review&lt;/strong>: Thorough peer review processes for quality control&lt;/li>
&lt;li>&lt;strong>Documentation&lt;/strong>: Comprehensive documentation practices for code and systems&lt;/li>
&lt;/ul>
&lt;h3 id="data-engineering-1">Data Engineering&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Data Mesh&lt;/strong>: Domain-oriented data ownership and architecture&lt;/li>
&lt;li>&lt;strong>Data Lake Design&lt;/strong>: Multi-tiered data lake organization (raw, bronze, silver, gold)&lt;/li>
&lt;li>&lt;strong>Data Observability&lt;/strong>: Monitoring data quality, freshness, and system health&lt;/li>
&lt;li>&lt;strong>Incremental Processing&lt;/strong>: Efficient handling of data updates and changes&lt;/li>
&lt;li>&lt;strong>Schema Evolution&lt;/strong>: Managing changing data structures over time&lt;/li>
&lt;/ul>
&lt;h3 id="machine-learning">Machine Learning&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>ML Project Lifecycle&lt;/strong>: From problem definition to deployment and monitoring&lt;/li>
&lt;li>&lt;strong>Experiment Tracking&lt;/strong>: Systematic recording of ML experiments and results&lt;/li>
&lt;li>&lt;strong>Model Evaluation&lt;/strong>: Rigorous testing and validation of model performance&lt;/li>
&lt;li>&lt;strong>Responsible AI&lt;/strong>: Ethical considerations, bias detection and mitigation&lt;/li>
&lt;li>&lt;strong>A/B Testing&lt;/strong>: Systematic approach to testing model improvements&lt;/li>
&lt;/ul>
&lt;h2 id="certifications--professional-development">Certifications &amp;amp; Professional Development&lt;/h2>
&lt;h3 id="current-certifications">Current Certifications&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>AWS Certified Solutions Architect – Associate&lt;/strong> (2023)&lt;/li>
&lt;li>&lt;strong>Google Professional Data Engineer&lt;/strong> (2024)&lt;/li>
&lt;li>&lt;strong>TensorFlow Developer Certificate&lt;/strong> (2023)&lt;/li>
&lt;li>&lt;strong>Microsoft Certified: Azure Data Engineer Associate&lt;/strong> (2024)&lt;/li>
&lt;/ul>
&lt;h3 id="continuous-learning">Continuous Learning&lt;/h3>
&lt;p>I&amp;rsquo;m committed to ongoing professional development. Currently, I&amp;rsquo;m:&lt;/p></description></item><item><title>Projects &amp; Portfolio</title><link>https://joaoblasques.com/projects/</link><pubDate>Fri, 20 Jun 2025 16:01:06 +0100</pubDate><guid>https://joaoblasques.com/projects/</guid><description>&lt;h2 id="professional-projects">Professional Projects&lt;/h2>
&lt;p>Here are some key projects I&amp;rsquo;ve led or contributed to significantly in my professional career:&lt;/p>
&lt;h3 id="real-time-customer-analytics-platform">Real-Time Customer Analytics Platform&lt;/h3>
&lt;p>&lt;strong>Client&lt;/strong>: Major E-commerce Retailer&lt;br>
&lt;strong>Timeline&lt;/strong>: 2023 - Present&lt;/p>
&lt;p>&lt;strong>Technologies Used&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Apache Kafka &amp;amp; Kafka Streams&lt;/li>
&lt;li>AWS (Lambda, Kinesis, S3, DynamoDB)&lt;/li>
&lt;li>Python, Spark Structured Streaming&lt;/li>
&lt;li>Kubernetes for orchestration&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Project Overview&lt;/strong>:&lt;br>
Designed and implemented a real-time customer analytics platform processing over 5TB of daily event data. The system captures user interactions, processes them through a sophisticated streaming pipeline, and feeds AI models that generate personalized recommendations in under 200ms.&lt;/p></description></item><item><title>About Me</title><link>https://joaoblasques.com/about/</link><pubDate>Fri, 20 Jun 2025 16:00:12 +0100</pubDate><guid>https://joaoblasques.com/about/</guid><description>&lt;h2 id="professional-summary">Professional Summary&lt;/h2>
&lt;p>I am João Blasques, an AI-Enabled Data Engineer with over 7 years of experience in designing, implementing, and optimizing data pipelines and machine learning solutions. I specialize in transforming complex data challenges into actionable insights and automated systems that drive business growth and operational efficiency.&lt;/p>
&lt;p>My career is built on a strong foundation in data engineering complemented by deep expertise in artificial intelligence and machine learning applications. I excel at bridging the gap between technical implementations and business objectives, ensuring that data solutions deliver measurable value.&lt;/p></description></item><item><title>The Role of AI in Modern Data Architectures</title><link>https://joaoblasques.com/post/the-role-of-ai-in-modern-data-architectures/</link><pubDate>Sun, 11 May 2025 12:15:00 +0100</pubDate><guid>https://joaoblasques.com/post/the-role-of-ai-in-modern-data-architectures/</guid><description>&lt;h2 id="ai-driven-data-architecture">AI-Driven Data Architecture&lt;/h2>
&lt;p>Artificial intelligence isn&amp;rsquo;t just a consumer of data—it&amp;rsquo;s increasingly becoming an integral part of how we design and operate our data systems. This post explores the evolving relationship between AI and data architecture.&lt;/p>
&lt;h3 id="ai-enhanced-data-processing">AI-Enhanced Data Processing&lt;/h3>
&lt;p>Modern data architectures are incorporating AI at various levels:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Intelligent Data Cataloging&lt;/strong> - Automatically discovering, classifying, and tagging data assets&lt;/li>
&lt;li>&lt;strong>Adaptive Data Integration&lt;/strong> - Using ML to identify optimal integration patterns and transformations&lt;/li>
&lt;li>&lt;strong>Automated Quality Management&lt;/strong> - Detecting anomalies and quality issues without manual rules&lt;/li>
&lt;li>&lt;strong>Self-Tuning Systems&lt;/strong> - Databases and data platforms that optimize themselves based on workloads&lt;/li>
&lt;/ul>
&lt;h3 id="real-world-applications">Real-World Applications&lt;/h3>
&lt;h4 id="recommendation-systems">Recommendation Systems&lt;/h4>
&lt;p>AI algorithms help determine which data is most relevant to different users and use cases, optimizing data discovery and access.&lt;/p></description></item><item><title>Machine Learning Pipeline Design</title><link>https://joaoblasques.com/post/ml-pipeline-design/</link><pubDate>Fri, 09 May 2025 10:45:00 +0100</pubDate><guid>https://joaoblasques.com/post/ml-pipeline-design/</guid><description>&lt;h2 id="building-effective-machine-learning-pipelines">Building Effective Machine Learning Pipelines&lt;/h2>
&lt;p>Creating robust machine learning pipelines is essential for deploying AI solutions at scale. This post covers key considerations and best practices.&lt;/p>
&lt;h3 id="the-anatomy-of-an-ml-pipeline">The Anatomy of an ML Pipeline&lt;/h3>
&lt;p>A well-designed ML pipeline includes these key stages:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Data Ingestion&lt;/strong> - Collecting and importing data from various sources&lt;/li>
&lt;li>&lt;strong>Data Preparation&lt;/strong> - Cleaning, transforming, and feature engineering&lt;/li>
&lt;li>&lt;strong>Model Training&lt;/strong> - Developing and tuning ML models&lt;/li>
&lt;li>&lt;strong>Model Evaluation&lt;/strong> - Assessing performance and validity&lt;/li>
&lt;li>&lt;strong>Model Deployment&lt;/strong> - Serving models in production environments&lt;/li>
&lt;li>&lt;strong>Monitoring&lt;/strong> - Tracking performance and detecting drift&lt;/li>
&lt;/ol>
&lt;h3 id="common-challenges-and-solutions">Common Challenges and Solutions&lt;/h3>
&lt;h4 id="challenge-data-quality-issues">Challenge: Data Quality Issues&lt;/h4>
&lt;p>&lt;strong>Solution&lt;/strong>: Implement robust data validation and cleaning processes early in the pipeline.&lt;/p></description></item><item><title>Getting Started with Data Engineering</title><link>https://joaoblasques.com/post/getting-started-with-data-engineering/</link><pubDate>Mon, 05 May 2025 09:30:00 +0100</pubDate><guid>https://joaoblasques.com/post/getting-started-with-data-engineering/</guid><description>&lt;h2 id="data-engineering-fundamentals">Data Engineering Fundamentals&lt;/h2>
&lt;p>Data engineering is the backbone of any data-driven organization. In this post, we will explore the fundamental concepts that every aspiring data engineer should understand.&lt;/p>
&lt;h3 id="what-is-data-engineering">What is Data Engineering?&lt;/h3>
&lt;p>Data engineering focuses on designing, building, and maintaining the infrastructure and architecture for data generation, storage, and analysis. Data engineers develop the systems that collect, manage, and convert raw data into usable information for data scientists and business analysts.&lt;/p></description></item><item><title>Welcome to My Professional Website</title><link>https://joaoblasques.com/post/welcome/</link><pubDate>Wed, 23 Apr 2025 15:55:33 +0100</pubDate><guid>https://joaoblasques.com/post/welcome/</guid><description>&lt;h2 id="hello-im-joão-blasques">Hello, I&amp;rsquo;m João Blasques&lt;/h2>
&lt;p>Welcome to my professional website! I&amp;rsquo;m an AI-Enabled Data Engineer passionate about leveraging artificial intelligence and data solutions to solve complex business problems.&lt;/p>
&lt;h3 id="my-background">My Background&lt;/h3>
&lt;p>With expertise in data engineering, machine learning, and AI integration, I help organizations transform their data into actionable insights. I specialize in designing and implementing data pipelines, creating machine learning models, and developing AI-powered applications that drive business value.&lt;/p>
&lt;h3 id="what-youll-find-here">What You&amp;rsquo;ll Find Here&lt;/h3>
&lt;p>On this website, you can explore:&lt;/p></description></item><item><title/><link>https://joaoblasques.com/readme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://joaoblasques.com/readme/</guid><description>&lt;h1 id="hello-im-joão-blasques">Hello, I&amp;rsquo;m João Blasques&lt;/h1>
&lt;p>Welcome to my professional website. I&amp;rsquo;m an AI-Enabled Data Engineer with over 5 years of experience in the tech and programming space and 1 year of experience in designing, implementing, and optimizing data pipelines and machine learning solutions.&lt;/p>
&lt;h2 id="about-me">About Me&lt;/h2>
&lt;p>I specialize in data engineering, artificial intelligence, and machine learning applications. My expertise includes ETL/ELT pipelines, cloud platforms (AWS, GCP, Azure), DevOps and MLOps. I believe in transforming complex data challenges into actionable insights and automated systems that drive business growth and operational efficiency.&lt;/p></description></item></channel></rss>