<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bigquery on João Blasques | AI-Enabled Data Engineer</title>
    <link>http://localhost:1313/tags/bigquery/</link>
    <description>Recent content in Bigquery on João Blasques | AI-Enabled Data Engineer</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Jul 2025 00:00:00 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/bigquery/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building a Data Pipeline with BigQuery: From Storage to Analytics</title>
      <link>http://localhost:1313/post/data-warehouse-bigquery-pipeline/</link>
      <pubDate>Mon, 14 Jul 2025 00:00:00 +0100</pubDate>
      <guid>http://localhost:1313/post/data-warehouse-bigquery-pipeline/</guid>
      <description>&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;&#xA;&lt;p&gt;This project demonstrates the implementation of a comprehensive data pipeline using Google BigQuery as the primary data warehouse solution. The pipeline showcases modern data engineering practices including external data integration, table optimization strategies, and performance tuning techniques.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Repository:&lt;/strong&gt; &lt;a href=&#34;https://github.com/jonasblasques/4-data-pipeline-datawarehouse-bigquery&#34;&gt;Data Pipeline with BigQuery&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;The project focuses on building a scalable, cost-effective data warehouse solution that can handle large volumes of NYC taxi trip data while maintaining optimal query performance and cost efficiency.&lt;/p&gt;&#xA;&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;&#xA;&lt;p&gt;• &lt;strong&gt;OLAP vs OLTP:&lt;/strong&gt; Understanding the fundamental differences between Online Analytical Processing and Online Transaction Processing systems&#xA;• &lt;strong&gt;Data Warehousing:&lt;/strong&gt; Implementing centralized storage for analytical workloads with optimized query performance&#xA;• &lt;strong&gt;Table Partitioning:&lt;/strong&gt; Dividing large tables into manageable chunks based on time or range values&#xA;• &lt;strong&gt;Clustering:&lt;/strong&gt; Organizing data within partitions to improve query performance and reduce costs&#xA;• &lt;strong&gt;External Tables:&lt;/strong&gt; Querying data stored outside BigQuery without incurring storage costs&#xA;• &lt;strong&gt;Performance Optimization:&lt;/strong&gt; Implementing best practices for cost reduction and query efficiency&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Pipeline Orchestration using Kestra</title>
      <link>http://localhost:1313/post/data-pipeline-orchestration-kestra/</link>
      <pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate>
      <guid>http://localhost:1313/post/data-pipeline-orchestration-kestra/</guid>
      <description>&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;&#xA;&lt;p&gt;This &lt;a href=&#34;https://github.com/joaoblasques/data-pipeline-orchestration-kestra&#34;&gt;repository&lt;/a&gt; demonstrates workflow orchestration for data engineering pipelines using &lt;a href=&#34;https://kestra.io/&#34;&gt;Kestra&lt;/a&gt;. It guides users through building, running, and scheduling data pipelines that extract, transform, and load (ETL) data both locally (with PostgreSQL) and in the cloud (with Google Cloud Platform). The project is hands-on and includes conceptual explanations, infrastructure setup, and several example pipeline flows.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Workflow Orchestration:&lt;/strong&gt; Automating and managing complex workflows with dependencies, retries, logging, and monitoring.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Kestra:&lt;/strong&gt; An orchestration platform with a user-friendly UI and YAML-based workflow definitions (called &amp;ldquo;flows&amp;rdquo;).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Lake &amp;amp; Data Warehouse:&lt;/strong&gt; Demonstrates moving data from raw storage (GCS) to structured analytics (BigQuery).&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Orchestrating Data Pipelines with Apache Airflow: A Comprehensive Guide</title>
      <link>http://localhost:1313/post/data-pipeline-orchestration-airflow/</link>
      <pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate>
      <guid>http://localhost:1313/post/data-pipeline-orchestration-airflow/</guid>
      <description>&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;&#xA;&lt;p&gt;This &lt;a href=&#34;https://github.com/joaoblasques/data-pipeline-orchestration-airflow&#34;&gt;repository&lt;/a&gt; serves as a practical guide to building and orchestrating robust data pipelines using Apache Airflow. It covers essential concepts from basic workflow management to advanced deployments with Google Cloud Platform (GCP) and Kubernetes.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;key-concepts&#34;&gt;Key Concepts&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Workflow Orchestration:&lt;/strong&gt; Automating and managing complex data workflows with dependencies, scheduling, retries, and monitoring using Apache Airflow.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DAGs (Directed Acyclic Graphs):&lt;/strong&gt; The core abstraction in Airflow for defining task dependencies, execution order, and workflow logic.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Extensible Operators &amp;amp; Integrations:&lt;/strong&gt; Leveraging Airflow&amp;rsquo;s wide range of built-in operators and custom plugins to interact with databases, cloud services (GCP, Kubernetes), and external systems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scalable Deployments:&lt;/strong&gt; Running Airflow locally for prototyping, or deploying on cloud and Kubernetes for production-scale, resilient, and distributed data pipeline execution.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
