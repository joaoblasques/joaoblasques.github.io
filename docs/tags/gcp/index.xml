<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gcp on João Blasques | AI-Enabled Data Engineer</title><link>https://joaoblasques.com/tags/gcp/</link><description>Recent content in Gcp on João Blasques | AI-Enabled Data Engineer</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 21 Jun 2025 09:30:00 +0100</lastBuildDate><atom:link href="https://joaoblasques.com/tags/gcp/index.xml" rel="self" type="application/rss+xml"/><item><title>Orchestrating Data Pipelines with Apache Airflow: A Comprehensive Guide</title><link>https://joaoblasques.com/post/data-pipeline-orchestration-airflow/</link><pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate><guid>https://joaoblasques.com/post/data-pipeline-orchestration-airflow/</guid><description>&lt;h2 id="project-overview">Project Overview&lt;/h2>
&lt;p>This &lt;a href="https://github.com/joaoblasques/data-pipeline-orchestration-airflow">repository&lt;/a> serves as a practical guide to building and orchestrating robust data pipelines using Apache Airflow. It covers essential concepts from basic workflow management to advanced deployments with Google Cloud Platform (GCP) and Kubernetes.&lt;/p>
&lt;hr>
&lt;h2 id="key-concepts">Key Concepts&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Workflow Orchestration:&lt;/strong> Automating and managing complex data workflows with dependencies, scheduling, retries, and monitoring using Apache Airflow.&lt;/li>
&lt;li>&lt;strong>DAGs (Directed Acyclic Graphs):&lt;/strong> The core abstraction in Airflow for defining task dependencies, execution order, and workflow logic.&lt;/li>
&lt;li>&lt;strong>Extensible Operators &amp;amp; Integrations:&lt;/strong> Leveraging Airflow&amp;rsquo;s wide range of built-in operators and custom plugins to interact with databases, cloud services (GCP, Kubernetes), and external systems.&lt;/li>
&lt;li>&lt;strong>Scalable Deployments:&lt;/strong> Running Airflow locally for prototyping, or deploying on cloud and Kubernetes for production-scale, resilient, and distributed data pipeline execution.&lt;/li>
&lt;/ul></description></item><item><title>Simple Data Pipeline</title><link>https://joaoblasques.com/post/data-pipeline-simple/</link><pubDate>Sat, 21 Jun 2025 09:30:00 +0100</pubDate><guid>https://joaoblasques.com/post/data-pipeline-simple/</guid><description>&lt;h2 id="project-overview">Project Overview&lt;/h2>
&lt;p>This &lt;a href="https://github.com/joaoblasques/data-pipeline-simple">repository&lt;/a> provides a comprehensive, step-by-step guide to building a simple data engineering pipeline using containerization (Docker), orchestration (Docker Compose), and Infrastructure as Code (Terraform), with a focus on ingesting and processing NYC taxi data. The project is hands-on and includes conceptual explanations, infrastructure setup, and several example pipeline flows.&lt;/p>
&lt;p>This project is a practical template for data engineers to learn and implement containerized data pipelines, local and cloud database management, and automated cloud infrastructure provisioning using modern tools like Docker, Docker Compose, and Terraform. It is especially useful for those looking to understand the end-to-end workflow from local prototyping to cloud deployment in a reproducible, automated way.&lt;/p></description></item></channel></rss>